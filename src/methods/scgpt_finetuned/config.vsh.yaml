__merge__: ../../api/base_method.yaml

name: scgpt_finetuned
label: scGPT (fine-tuned)
summary: "Cell-type annotation by fine-tuning on a pre-trained scGPT model."
description: |
  scGPT is a foundation model for single-cell biology based on a generative pre-trained transformer and trained on a repository of over 33 million cells. Here, we fine-tune a pre-trained model on a reference dataset using the hyper-parameter recommenations for the cell-type task and then infer cell-types for the unlabelled cells in a query dataset.

references:
  doi: 10.1038/s41592-024-02201-0

links:
  documentation: https://scgpt.readthedocs.io/en/latest/
  repository: https://github.com/bowang-lab/scGPT

info:
  preferred_normalization: counts

arguments:
  - name: --model_name
    type: string
    description: String giving the name of the scGPT model to use
    choices: ["scGPT_human", "scGPT_CP"]
    default: "scGPT_human"
  - name: --model
    type: file
    description: Path to the directory containing the scGPT model specified by model_name or a .zip/.tar.gz archive to extract. If not given the model will be downloaded.
    required: false

resources:
  - type: python_script
    path: script.py
  - path: functions.py
  - path: /src/utils/exit_codes.py

engines:
  - type: docker
    image: openproblems/base_pytorch_nvidia:1
    setup:
      - type: docker
        run: |
          git clone https://github.com/bowang-lab/scGPT && \
          pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu121 && \
          pip install "flash-attn<1.0.5" --no-build-isolation && \
          pip install ipykernel pandas scanpy numba "numpy<1.24" torchtext==0.17.0 scib "scvi-tools<1.0" datasets==2.14.5 transformers==4.33.2 wandb "cell-gears<0.0.3" torch_geometric pyarrow==15.0.0 gdown && \
          cd scGPT && pip install -e . --no-deps

runners:
  - type: executable
    # docker_run_args: "--gpus all"
  - type: nextflow
    directives:
      label: [midtime, highmem, midcpu, biggpu, midsharedmem]
